#!/bin/bash

# CUDA ve GPU Setup Script for Zeytin AÄŸacÄ± Analiz Sistemi
# NVIDIA GPU, CUDA, CuDNN kurulumu ve yapÄ±landÄ±rmasÄ±

set -e

echo "ğŸš€ CUDA ve GPU Kurulum Scripti BaÅŸlatÄ±lÄ±yor..."

# Renkli Ã§Ä±ktÄ± iÃ§in
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Log dosyasÄ±
LOG_FILE="/var/log/cuda-setup.log"

log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Root kontrolÃ¼
check_root() {
    if [ "$EUID" -ne 0 ]; then
        print_error "Bu script root yetkileri ile Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±dÄ±r"
        exit 1
    fi
}

# GPU kontrolÃ¼
check_gpu() {
    print_status "GPU kontrolÃ¼ yapÄ±lÄ±yor..."
    log_message "GPU kontrolÃ¼ baÅŸlatÄ±ldÄ±"
    
    if lspci | grep -i nvidia >/dev/null 2>&1; then
        GPU_INFO=$(lspci | grep -i nvidia | head -1)
        print_success "NVIDIA GPU tespit edildi: $GPU_INFO"
        log_message "NVIDIA GPU tespit edildi: $GPU_INFO"
        return 0
    else
        print_error "NVIDIA GPU tespit edilemedi"
        log_message "NVIDIA GPU tespit edilemedi"
        print_status "Desteklenen GPU'lar:"
        echo "- NVIDIA GeForce GTX 1060 ve Ã¼zeri"
        echo "- NVIDIA RTX serisi"
        echo "- NVIDIA Tesla serisi"
        echo "- NVIDIA Quadro serisi"
        exit 1
    fi
}

# Mevcut NVIDIA driver kontrolÃ¼
check_existing_drivers() {
    print_status "Mevcut NVIDIA driver'larÄ± kontrol ediliyor..."
    log_message "Mevcut driver kontrolÃ¼ baÅŸlatÄ±ldÄ±"
    
    if command -v nvidia-smi &> /dev/null; then
        DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
        print_warning "NVIDIA driver zaten kurulu: v$DRIVER_VERSION"
        log_message "Mevcut NVIDIA driver: v$DRIVER_VERSION"
        
        # Driver versiyonu kontrolÃ¼ (CUDA 12.1 iÃ§in minimum 525.60.13)
        if [ "$(echo "$DRIVER_VERSION >= 525.60" | bc -l)" -eq 1 ]; then
            print_success "Driver versiyonu CUDA 12.1 iÃ§in uygun"
            return 0
        else
            print_warning "Driver versiyonu eski, gÃ¼ncelleme gerekebilir"
            return 1
        fi
    else
        print_status "NVIDIA driver bulunamadÄ±, kurulum gerekli"
        log_message "NVIDIA driver bulunamadÄ±"
        return 1
    fi
}

# NVIDIA driver kurulumu
install_nvidia_driver() {
    print_status "NVIDIA driver kurulumu baÅŸlatÄ±lÄ±yor..."
    log_message "NVIDIA driver kurulumu baÅŸlatÄ±ldÄ±"
    
    # Nouveau driver'Ä± devre dÄ±ÅŸÄ± bÄ±rak
    print_status "Nouveau driver devre dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±yor..."
    echo 'blacklist nouveau' | tee /etc/modprobe.d/blacklist-nouveau.conf
    echo 'options nouveau modeset=0' | tee -a /etc/modprobe.d/blacklist-nouveau.conf
    update-initramfs -u
    
    # Sistem gÃ¼ncellemesi
    apt-get update
    
    # NVIDIA driver repository ekle
    add-apt-repository ppa:graphics-drivers/ppa -y
    apt-get update
    
    # En son driver'Ä± kur
    print_status "NVIDIA driver kuruluyor..."
    apt-get install -y nvidia-driver-535 nvidia-dkms-535
    
    print_success "NVIDIA driver kuruldu"
    print_warning "Sistem yeniden baÅŸlatÄ±lmasÄ± gerekiyor"
    log_message "NVIDIA driver kurulumu tamamlandÄ±"
}

# CUDA Toolkit kurulumu
install_cuda() {
    print_status "CUDA Toolkit kurulumu baÅŸlatÄ±lÄ±yor..."
    log_message "CUDA kurulumu baÅŸlatÄ±ldÄ±"
    
    # CUDA repository ekle
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
    dpkg -i cuda-keyring_1.0-1_all.deb
    apt-get update
    
    # CUDA 12.1 kurulumu
    print_status "CUDA 12.1 kuruluyor..."
    apt-get install -y cuda-toolkit-12-1
    
    # Environment variables
    echo 'export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}}' >> /etc/environment
    echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> /etc/environment
    
    # Bashrc'ye de ekle
    echo 'export PATH=/usr/local/cuda-12.1/bin${PATH:+:${PATH}}' >> ~/.bashrc
    echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc
    
    # Symlink oluÅŸtur
    ln -sf /usr/local/cuda-12.1 /usr/local/cuda
    
    print_success "CUDA Toolkit kuruldu"
    log_message "CUDA kurulumu tamamlandÄ±"
}

# CuDNN kurulumu
install_cudnn() {
    print_status "CuDNN kurulumu baÅŸlatÄ±lÄ±yor..."
    log_message "CuDNN kurulumu baÅŸlatÄ±ldÄ±"
    
    # CuDNN repository ekle
    apt-get install -y libcudnn8 libcudnn8-dev
    
    print_success "CuDNN kuruldu"
    log_message "CuDNN kurulumu tamamlandÄ±"
}

# Docker GPU desteÄŸi
setup_docker_gpu() {
    print_status "Docker GPU desteÄŸi kurulumu..."
    log_message "Docker GPU desteÄŸi kurulumu baÅŸlatÄ±ldÄ±"
    
    # NVIDIA Container Toolkit repository
    distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
    curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
    curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
    
    apt-get update
    apt-get install -y nvidia-container-toolkit
    
    # Docker'Ä± yeniden yapÄ±landÄ±r
    nvidia-ctk runtime configure --runtime=docker
    systemctl restart docker
    
    print_success "Docker GPU desteÄŸi kuruldu"
    log_message "Docker GPU desteÄŸi kurulumu tamamlandÄ±"
}

# GPU test scripti oluÅŸtur
create_gpu_test() {
    print_status "GPU test scripti oluÅŸturuluyor..."
    log_message "GPU test scripti oluÅŸturma baÅŸlatÄ±ldÄ±"
    
    cat > /usr/local/bin/gpu-test.py << 'EOF'
#!/usr/bin/env python3
"""
GPU Test Script for Zeytin AÄŸacÄ± Analiz Sistemi
CUDA, PyTorch ve YOLOv8 GPU desteÄŸini test eder
"""

import sys
import subprocess

def test_nvidia_smi():
    """NVIDIA SMI testi"""
    print("ğŸ” NVIDIA SMI Test...")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA SMI Ã§alÄ±ÅŸÄ±yor")
            print(result.stdout)
            return True
        else:
            print("âŒ NVIDIA SMI hatasÄ±")
            print(result.stderr)
            return False
    except FileNotFoundError:
        print("âŒ NVIDIA SMI bulunamadÄ±")
        return False

def test_cuda():
    """CUDA testi"""
    print("\nğŸ” CUDA Test...")
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… CUDA Compiler Ã§alÄ±ÅŸÄ±yor")
            print(result.stdout)
            return True
        else:
            print("âŒ CUDA Compiler hatasÄ±")
            return False
    except FileNotFoundError:
        print("âŒ CUDA Compiler bulunamadÄ±")
        return False

def test_pytorch():
    """PyTorch GPU testi"""
    print("\nğŸ” PyTorch GPU Test...")
    try:
        import torch
        print(f"PyTorch SÃ¼rÃ¼mÃ¼: {torch.__version__}")
        
        cuda_available = torch.cuda.is_available()
        print(f"CUDA Mevcut: {'âœ… Evet' if cuda_available else 'âŒ HayÄ±r'}")
        
        if cuda_available:
            gpu_count = torch.cuda.device_count()
            print(f"GPU SayÄ±sÄ±: {gpu_count}")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
            
            # Basit tensor testi
            try:
                x = torch.randn(1000, 1000).cuda()
                y = torch.randn(1000, 1000).cuda()
                z = torch.mm(x, y)
                print("âœ… GPU tensor iÅŸlemleri baÅŸarÄ±lÄ±")
                
                # Memory info
                allocated = torch.cuda.memory_allocated(0) / 1024**2
                cached = torch.cuda.memory_reserved(0) / 1024**2
                print(f"GPU Bellek: {allocated:.1f} MB (Allocated), {cached:.1f} MB (Cached)")
                
                return True
            except Exception as e:
                print(f"âŒ GPU tensor iÅŸlem hatasÄ±: {e}")
                return False
        else:
            return False
            
    except ImportError:
        print("âŒ PyTorch bulunamadÄ±")
        return False
    except Exception as e:
        print(f"âŒ PyTorch test hatasÄ±: {e}")
        return False

def test_ultralytics():
    """Ultralytics YOLOv8 GPU testi"""
    print("\nğŸ” YOLOv8 GPU Test...")
    try:
        from ultralytics import YOLO
        import torch
        
        if not torch.cuda.is_available():
            print("âŒ CUDA mevcut deÄŸil, YOLOv8 GPU testi atlanÄ±yor")
            return False
        
        print("YOLOv8 modeli yÃ¼kleniyor...")
        model = YOLO('yolov8n.pt')  # Nano model
        
        # GPU'ya taÅŸÄ±
        model.to('cuda')
        print("âœ… YOLOv8 modeli GPU'ya yÃ¼klendi")
        
        # Dummy prediction
        import numpy as np
        dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        print("GPU'da test prediction yapÄ±lÄ±yor...")
        results = model(dummy_image, device='cuda', verbose=False)
        print("âœ… YOLOv8 GPU prediction baÅŸarÄ±lÄ±")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Ultralytics import hatasÄ±: {e}")
        return False
    except Exception as e:
        print(f"âŒ YOLOv8 test hatasÄ±: {e}")
        return False

def test_docker_gpu():
    """Docker GPU testi"""
    print("\nğŸ” Docker GPU Test...")
    try:
        result = subprocess.run([
            'docker', 'run', '--rm', '--gpus', 'all',
            'nvidia/cuda:12.1-base-ubuntu22.04',
            'nvidia-smi'
        ], capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            print("âœ… Docker GPU desteÄŸi Ã§alÄ±ÅŸÄ±yor")
            return True
        else:
            print("âŒ Docker GPU test hatasÄ±")
            print(result.stderr)
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ Docker GPU test timeout")
        return False
    except FileNotFoundError:
        print("âŒ Docker bulunamadÄ±")
        return False
    except Exception as e:
        print(f"âŒ Docker GPU test hatasÄ±: {e}")
        return False

def main():
    """Ana test fonksiyonu"""
    print("ğŸš€ GPU Test Suite BaÅŸlatÄ±lÄ±yor...\n")
    
    tests = [
        ("NVIDIA SMI", test_nvidia_smi),
        ("CUDA", test_cuda),
        ("PyTorch", test_pytorch),
        ("YOLOv8", test_ultralytics),
        ("Docker GPU", test_docker_gpu)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name} test exception: {e}")
            results[test_name] = False
    
    # SonuÃ§larÄ± Ã¶zetle
    print("\n" + "="*50)
    print("ğŸ“Š TEST SONUÃ‡LARI")
    print("="*50)
    
    passed = 0
    total = len(tests)
    
    for test_name, result in results.items():
        status = "âœ… BAÅARILI" if result else "âŒ BAÅARISIZ"
        print(f"{test_name:15} : {status}")
        if result:
            passed += 1
    
    print(f"\nToplam: {passed}/{total} test baÅŸarÄ±lÄ±")
    
    if passed == total:
        print("ğŸ‰ TÃ¼m GPU testleri baÅŸarÄ±lÄ±!")
        return 0
    elif passed >= 3:
        print("âš ï¸  BazÄ± testler baÅŸarÄ±sÄ±z ama temel GPU desteÄŸi Ã§alÄ±ÅŸÄ±yor")
        return 0
    else:
        print("âŒ GPU desteÄŸi dÃ¼zgÃ¼n Ã§alÄ±ÅŸmÄ±yor")
        return 1

if __name__ == "__main__":
    sys.exit(main())
EOF

    chmod +x /usr/local/bin/gpu-test.py
    
    print_success "GPU test scripti oluÅŸturuldu: /usr/local/bin/gpu-test.py"
    log_message "GPU test scripti oluÅŸturuldu"
}

# Sistem optimizasyonlarÄ±
optimize_gpu_system() {
    print_status "GPU sistem optimizasyonlarÄ± yapÄ±lÄ±yor..."
    log_message "GPU sistem optimizasyonu baÅŸlatÄ±ldÄ±"
    
    # GPU memory optimizasyonlarÄ±
    cat >> /etc/sysctl.conf << 'EOF'

# GPU optimizasyonlarÄ±
vm.zone_reclaim_mode = 0
vm.swappiness = 1
kernel.numa_balancing = 0
EOF

    sysctl -p
    
    # GPU persistence mode
    if command -v nvidia-smi &> /dev/null; then
        nvidia-smi -pm 1 2>/dev/null || true
    fi
    
    print_success "GPU sistem optimizasyonlarÄ± tamamlandÄ±"
    log_message "GPU sistem optimizasyonu tamamlandÄ±"
}

# Ana kurulum fonksiyonu
main() {
    log_message "=== CUDA kurulumu baÅŸlatÄ±ldÄ± ==="
    
    check_root
    check_gpu
    
    # Mevcut driver kontrolÃ¼
    if ! check_existing_drivers; then
        print_warning "NVIDIA driver kurulumu gerekli"
        read -p "NVIDIA driver kurmak istiyor musunuz? (y/N): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            install_nvidia_driver
            print_warning "Sistem yeniden baÅŸlatÄ±lmasÄ± gerekiyor"
            print_status "Yeniden baÅŸlattÄ±ktan sonra bu scripti tekrar Ã§alÄ±ÅŸtÄ±rÄ±n"
            exit 0
        else
            print_error "NVIDIA driver olmadan devam edilemiyor"
            exit 1
        fi
    fi
    
    # CUDA kurulumu
    if ! command -v nvcc &> /dev/null; then
        install_cuda
    else
        print_warning "CUDA zaten kurulu"
        nvcc --version
    fi
    
    # CuDNN kurulumu
    install_cudnn
    
    # Docker GPU desteÄŸi
    if command -v docker &> /dev/null; then
        setup_docker_gpu
    else
        print_warning "Docker bulunamadÄ±, GPU desteÄŸi atlanÄ±yor"
    fi
    
    # Test scripti oluÅŸtur
    create_gpu_test
    
    # Sistem optimizasyonlarÄ±
    optimize_gpu_system
    
    print_success "ğŸ‰ CUDA kurulumu tamamlandÄ±!"
    print_status "GPU testini Ã§alÄ±ÅŸtÄ±rmak iÃ§in: python3 /usr/local/bin/gpu-test.py"
    
    # Otomatik test Ã§alÄ±ÅŸtÄ±r
    print_status "GPU testi Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor..."
    if python3 /usr/local/bin/gpu-test.py; then
        print_success "GPU testleri baÅŸarÄ±lÄ±!"
    else
        print_warning "BazÄ± GPU testleri baÅŸarÄ±sÄ±z"
    fi
    
    log_message "=== CUDA kurulumu tamamlandÄ± ==="
}

# Script'i Ã§alÄ±ÅŸtÄ±r
main "$@"